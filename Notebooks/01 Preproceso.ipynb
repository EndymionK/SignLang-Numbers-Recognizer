{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento del dataset \"Sign Language for Numbers\"\n",
    "\n",
    "Este notebook automatiza la descarga, extracción y preprocesamiento de imágenes del dataset de Kaggle [\"Sign Language for Numbers\"](https://www.kaggle.com/datasets/muhammadkhalid/sign-language-for-numbers).\n",
    "\n",
    "Ahora el preprocesamiento utiliza MediaPipe Hands para detectar y recortar la mano en cada imagen, y además extrae los puntos clave (landmarks) de la mano para usarlos como características para la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías necesarias\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Descargar y extraer el dataset desde Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/muhammadkhalid/sign-language-for-numbers\n"
     ]
    }
   ],
   "source": [
    "dataset_kaggle = \"muhammadkhalid/sign-language-for-numbers\"\n",
    "dataset_dir = \"../Sign Language for Numbers\"\n",
    "\n",
    "# Configura las variables de entorno para la autenticación de Kaggle\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"andrsarroyavec\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"4b25dc17e4be3312ddb048800c3c2903\"\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Descargar y extraer el dataset completo (no un archivo específico)\n",
    "if not os.path.exists(dataset_dir):\n",
    "    api.dataset_download_files(dataset_kaggle, path=\"..\", unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definir rutas y clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpetas de entrada y salida\n",
    "input_dir = \"../Sign Language for Numbers\"\n",
    "output_dir = \"../preprocessed_numbers\"\n",
    "classes = [str(i) for i in range(10)] + [\"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpetas de salida\n",
    "for c in classes:\n",
    "    os.makedirs(os.path.join(output_dir, c), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Función de preprocesamiento de imágenes con MediaPipe\n",
    "\n",
    "- Detecta la mano con MediaPipe\n",
    "- Recorta la región de la mano (con margen)\n",
    "- Redimensiona a 128x128\n",
    "- Convierte a escala de grises\n",
    "- Normaliza a [0,1]\n",
    "- Extrae los puntos clave (landmarks) de la mano y los retorna como vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "def get_hand_bbox(landmarks, img_shape, margin=20):\n",
    "    h, w = img_shape[:2]\n",
    "    x_coords = [int(l.x * w) for l in landmarks]\n",
    "    y_coords = [int(l.y * h) for l in landmarks]\n",
    "    x_min, x_max = max(min(x_coords) - margin, 0), min(max(x_coords) + margin, w)\n",
    "    y_min, y_max = max(min(y_coords) - margin, 0), min(max(y_coords) + margin, h)\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def extract_landmarks(landmarks, img_shape):\n",
    "    h, w = img_shape[:2]\n",
    "    # Devuelve un vector plano con las coordenadas normalizadas (x, y, z) de cada punto\n",
    "    return np.array([[l.x, l.y, l.z] for l in landmarks]).flatten()\n",
    "\n",
    "def preprocess_image_mediapipe(img_path, size=(128, 128)):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return None, None\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    with mp_hands.Hands(static_image_mode=True, max_num_hands=1) as hands:\n",
    "        results = hands.process(img_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0].landmark\n",
    "            x_min, y_min, x_max, y_max = get_hand_bbox(hand_landmarks, img.shape)\n",
    "            hand_img = img[y_min:y_max, x_min:x_max]\n",
    "            if hand_img.size == 0:\n",
    "                return None, None\n",
    "            hand_img = cv2.cvtColor(hand_img, cv2.COLOR_BGR2GRAY)\n",
    "            hand_img = cv2.resize(hand_img, size)\n",
    "            hand_img = hand_img.astype(np.float32) / 255.0\n",
    "            landmarks_vec = extract_landmarks(hand_landmarks, img.shape)\n",
    "            return hand_img, landmarks_vec\n",
    "        else:\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Previsualización: Imagen original vs recorte y puntos de la mano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import urllib.request\n",
    "\n",
    "def download_mediapipe_model(model_url, model_path):\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Descargando modelo MediaPipe: {model_path}\")\n",
    "        urllib.request.urlretrieve(model_url, model_path)\n",
    "\n",
    "# Ruta y URL del modelo necesario para MediaPipe Hands\n",
    "mp_model_dir = os.path.join(os.path.dirname(mp.__file__), \"modules\", \"hand_landmark\")\n",
    "mp_model_file = os.path.join(mp_model_dir, \"hand_landmark_tracking_cpu.binarypb\")\n",
    "mp_model_url = \"https://storage.googleapis.com/mediapipe-assets/hand_landmark_tracking_cpu.binarypb\"\n",
    "\n",
    "download_mediapipe_model(mp_model_url, mp_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'Sign Language for Numbers\\\\0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m classes:\n\u001b[0;32m      4\u001b[0m     input_class_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, c)\n\u001b[1;32m----> 5\u001b[0m     files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_class_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m files:\n\u001b[0;32m      7\u001b[0m         ejemplos\u001b[38;5;241m.\u001b[39mappend((c, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_class_dir, files[\u001b[38;5;241m0\u001b[39m])))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'Sign Language for Numbers\\\\0'"
     ]
    }
   ],
   "source": [
    "# Selecciona algunas imágenes de ejemplo para mostrar el proceso de recorte y landmarks\n",
    "ejemplos = []\n",
    "for c in classes:\n",
    "    input_class_dir = os.path.join(input_dir, c)\n",
    "    files = [f for f in os.listdir(input_class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if files:\n",
    "        ejemplos.append((c, os.path.join(input_class_dir, files[0])))\n",
    "    if len(ejemplos) >= 5:\n",
    "        break\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "fig, axs = plt.subplots(len(ejemplos), 3, figsize=(12, 3*len(ejemplos)))\n",
    "if len(ejemplos) == 1:\n",
    "    axs = [axs]  # Para el caso de un solo ejemplo\n",
    "\n",
    "for idx, (clase, img_path) in enumerate(ejemplos):\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axs[idx][0].imshow(img_rgb)\n",
    "    axs[idx][0].set_title(f\"Original ({clase})\")\n",
    "    axs[idx][0].axis('off')\n",
    "\n",
    "    # Procesar con mediapipe\n",
    "    with mp_hands.Hands(static_image_mode=True, max_num_hands=1) as hands:\n",
    "        results = hands.process(img_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0].landmark\n",
    "            # Dibuja los puntos sobre la imagen original\n",
    "            img_landmarks = img_rgb.copy()\n",
    "            mp_drawing.draw_landmarks(img_landmarks, results.multi_hand_landmarks[0], mp_hands.HAND_CONNECTIONS)\n",
    "            axs[idx][1].imshow(img_landmarks)\n",
    "            axs[idx][1].set_title(\"Original + Landmarks\")\n",
    "            axs[idx][1].axis('off')\n",
    "\n",
    "            # Recorte y preprocesado\n",
    "            x_min, y_min, x_max, y_max = get_hand_bbox(hand_landmarks, img.shape)\n",
    "            hand_img = img[y_min:y_max, x_min:x_max]\n",
    "            if hand_img.size > 0:\n",
    "                hand_img = cv2.cvtColor(hand_img, cv2.COLOR_BGR2GRAY)\n",
    "                hand_img = cv2.resize(hand_img, (128, 128))\n",
    "                axs[idx][2].imshow(hand_img, cmap='gray')\n",
    "                axs[idx][2].set_title(\"Recorte mano\")\n",
    "                axs[idx][2].axis('off')\n",
    "            else:\n",
    "                axs[idx][2].axis('off')\n",
    "        else:\n",
    "            axs[idx][1].axis('off')\n",
    "            axs[idx][2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Procesar y guardar imágenes preprocesadas y puntos clave (landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_data = []\n",
    "\n",
    "for c in classes:\n",
    "    input_class_dir = os.path.join(input_dir, c)\n",
    "    output_class_dir = os.path.join(output_dir, c)\n",
    "    if not os.path.exists(input_class_dir):\n",
    "        print(f\"Carpeta no encontrada: {input_class_dir}\")\n",
    "        continue\n",
    "    files = [f for f in os.listdir(input_class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    for fname in tqdm(files, desc=f\"Procesando clase {c}\"):\n",
    "        in_path = os.path.join(input_class_dir, fname)\n",
    "        out_path = os.path.join(output_class_dir, fname)\n",
    "        img, landmarks_vec = preprocess_image_mediapipe(in_path)\n",
    "        if img is not None and landmarks_vec is not None:\n",
    "            cv2.imwrite(out_path, (img * 255).astype(np.uint8))\n",
    "            # Guardar los landmarks junto con la clase y el nombre de archivo\n",
    "            landmarks_data.append({\n",
    "                \"class\": c,\n",
    "                \"filename\": fname,\n",
    "                **{f\"lm_{i}\": v for i, v in enumerate(landmarks_vec)}\n",
    "            })\n",
    "\n",
    "# Guardar los landmarks en un archivo CSV\n",
    "if landmarks_data:\n",
    "    df_landmarks = pd.DataFrame(landmarks_data)\n",
    "    df_landmarks.to_csv(os.path.join(output_dir, \"landmarks.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizar ejemplos preprocesados y puntos clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for idx, c in enumerate(classes[:10]):\n",
    "    class_dir = os.path.join(output_dir, c)\n",
    "    img_files = os.listdir(class_dir)\n",
    "    img_files = [f for f in img_files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if img_files:\n",
    "        img_path = os.path.join(class_dir, img_files[0])\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        axs[idx//5, idx%5].imshow(img, cmap='gray')\n",
    "        axs[idx//5, idx%5].set_title(f\"Clase {c}\")\n",
    "        axs[idx//5, idx%5].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar algunos landmarks\n",
    "if os.path.exists(os.path.join(output_dir, \"landmarks.csv\")):\n",
    "    df_landmarks = pd.read_csv(os.path.join(output_dir, \"landmarks.csv\"))\n",
    "    display(df_landmarks.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Listo! Las imágenes preprocesadas (recortes de mano) y los puntos clave (landmarks) están en la carpeta `preprocessed_numbers`, organizadas por clase y con los landmarks en un archivo CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizar imágenes preprocesadas con puntos clave sobrepuestas\n",
    "\n",
    "A continuación se muestran ejemplos de imágenes recortadas con los puntos clave (landmarks) dibujados encima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar solo algunos ejemplos de imágenes preprocesadas con los puntos clave sobre ellas\n",
    "import random\n",
    "\n",
    "if os.path.exists(os.path.join(output_dir, \"landmarks.csv\")):\n",
    "    df_landmarks = pd.read_csv(os.path.join(output_dir, \"landmarks.csv\"))\n",
    "    # Selecciona aleatoriamente hasta 2 ejemplos por clase (máximo 10 clases)\n",
    "    ejemplos = []\n",
    "    for c in classes[:10]:\n",
    "        df_c = df_landmarks[df_landmarks[\"class\"] == c]\n",
    "        if len(df_c) > 0:\n",
    "            ejemplos += df_c.sample(n=min(2, len(df_c)), random_state=42).to_dict(\"records\")\n",
    "    n_ejemplos = len(ejemplos)\n",
    "    ncols = 3\n",
    "    nrows = (n_ejemplos + ncols - 1) // ncols\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(4*ncols, 4*nrows))\n",
    "    axs = axs.flatten()\n",
    "    for i, row in enumerate(ejemplos):\n",
    "        img_path = os.path.join(output_dir, str(row[\"class\"]), row[\"filename\"])\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        h, w = img.shape\n",
    "        # Los landmarks están normalizados respecto a la imagen original, no al recorte.\n",
    "        # Para que se superpongan correctamente, hay que recalcular los landmarks respecto al recorte.\n",
    "        # Solución: leer la imagen original, detectar la mano, obtener el bounding box y recalcular.\n",
    "        # Así, los puntos se dibujan correctamente sobre el recorte.\n",
    "        # --- Cargar imagen original y recalcular bbox ---\n",
    "        original_path = os.path.join(input_dir, str(row[\"class\"]), row[\"filename\"])\n",
    "        original_img = cv2.imread(original_path)\n",
    "        if original_img is not None:\n",
    "            img_rgb_draw = img_rgb.copy()\n",
    "            img_h, img_w = original_img.shape[:2]\n",
    "            # Reconstruir landmarks normalizados respecto a la imagen original\n",
    "            landmarks = np.array([row[f\"lm_{j}\"] for j in range(63)]).reshape(-1, 3)\n",
    "            # Obtener bbox de la mano en la imagen original\n",
    "            x_coords = [int(l[0] * img_w) for l in landmarks]\n",
    "            y_coords = [int(l[1] * img_h) for l in landmarks]\n",
    "            margin = 20\n",
    "            x_min, x_max = max(min(x_coords) - margin, 0), min(max(x_coords) + margin, img_w)\n",
    "            y_min, y_max = max(min(y_coords) - margin, 0), min(max(y_coords) + margin, img_h)\n",
    "            # Ajustar landmarks al recorte y a la escala 128x128\n",
    "            for (x, y, z) in landmarks:\n",
    "                # Coordenadas en la imagen original\n",
    "                px = x * img_w\n",
    "                py = y * img_h\n",
    "                # Coordenadas relativas al recorte\n",
    "                px_crop = px - x_min\n",
    "                py_crop = py - y_min\n",
    "                # Escalar a 128x128\n",
    "                px_final = int(px_crop * (128 / max(x_max - x_min, 1)))\n",
    "                py_final = int(py_crop * (128 / max(y_max - y_min, 1)))\n",
    "                cv2.circle(img_rgb_draw, (px_final, py_final), 2, (0,255,0), -1)\n",
    "            axs[i].imshow(img_rgb_draw)\n",
    "        else:\n",
    "            axs[i].imshow(img_rgb)\n",
    "        axs[i].set_title(f'{row[\"class\"]}: {row[\"filename\"]}')\n",
    "        axs[i].axis('off')\n",
    "    # Oculta los ejes vacíos si hay menos imágenes que subplots\n",
    "    for j in range(i+1, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No se encontró el archivo landmarks.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
